# RAG 教程 00：RAG 是什么？为什么要做？

RAG（Retrieval-Augmented Generation，检索增强生成）解决的是一个很实际的问题：

> 模型很会“说”，但不一定“知道你想让它依据的那份资料”，也不一定“知道最新的资料”。

RAG 的思想：让模型回答前先去查资料，再基于资料回答。

## 1. RAG 的典型流程（从 0 到 1）
1) 收集文档（Markdown、PDF、网页等）
2) 切块（Chunking）并保存元数据（source、标题路径等）
3) 对每个 chunk 做 embedding（向量化）
4) 建向量索引（FAISS / Milvus / pgvector …）
5) 查询时：
   - 问题向量化
   - 检索 TopK chunk
   - 将 chunk 拼到提示词上下文中
   - 生成答案并附引用

在 `demos/rag_min/` 里我们做的是“最小可跑通版本”：
- 重点打通 **切块 → 向量检索 → 引用输出**
- 生成阶段先用“模板式拼接”替代 LLM，确保链路可验证

## 2. RAG 带来的三类收益
- **降低幻觉**：回答基于检索片段，不用纯靠记忆编造
- **可追溯**：答案能指向来源（文档 + chunk id）
- **可扩展**：知识更新 = 更新索引，不必重新训练模型

## 3. RAG 的边界
RAG 不是万能：
- 检索不到资料：再强的生成也会“无米之炊”
- 资料本身有误：RAG 只会更“自信地引用错误”
- query/切块做得差：检索命中率低，整体效果差

因此，RAG 项目里“检索质量”往往比“模型大小”更关键。

---

## 📌 导航
- 上一章：建议先读 [Prompt 教程 20：Prompt 评估](../prompt/20_prompt_evaluation.md)
- 下一章：[RAG 教程 10：切块（Chunking）](./10_chunking.md)
- 返回总览：[根目录学习导航](../../README.md#-专题学习导航prompt--rag--skill)
